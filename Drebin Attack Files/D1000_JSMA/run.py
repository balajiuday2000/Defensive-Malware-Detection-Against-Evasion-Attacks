from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
from __future__ import unicode_literals


import numpy as np

from sklearn.model_selection import train_test_split
import random
from sklearn.preprocessing import OneHotEncoder
import logging
import numpy as np
from six.moves import xrange
import tensorflow as tf
tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)
from cleverhans.attacks import SaliencyMapMethod
from cleverhans.dataset import MNIST
from cleverhans.loss import CrossEntropy
from cleverhans.utils import other_classes, set_log_level
from cleverhans.utils import pair_visual, grid_visual, AccuracyReport
from cleverhans.utils_tf import model_eval, model_argmax
from cleverhans.train import train
from cleverhans import initializers

from cleverhans.model import Model

import functools





xben = np.load('xben.npy',allow_pickle=True)
yben = np.load('yben.npy',allow_pickle=True)

xmal = np.load('xmal.npy',allow_pickle=True)
ymal = np.load('ymal.npy',allow_pickle=True)



xmal.ndim




xmal.shape




print(type(xmal))




x_mal = xmal.astype('float32')
y_mal = ymal.astype('float32')
x_ben = xben.astype('float32')
y_ben = yben.astype('float32')





x_mal.shape





print(type(x_mal))





y_mal.shape





y_mal.shape




y_mal.ndim





x_ben.shape




y_ben.shape




X=[]
Y=[]
for i in x_mal:
    X.append(i)
for i in  x_ben:
    X.append(i)
for i in  y_mal:
    Y.append(i)
for i in  y_ben:
    Y.append(i)





Y[0]




Y[5559]


Y[5560]




X=np.asarray(X)


X.shape






random_state = random.randint(0, 1000)
#dataset is split into 60% training samples and 40% testing samples with stratification. 
train_idxs, test_idxs = train_test_split(
            range(X.shape[0]),
            test_size=0.4,
            random_state=random_state)



len(train_idxs)




len(test_idxs)




f_index_train_testsamples = f'indices-{random_state}.p'
import pickle
with open(f_index_train_testsamples, 'wb') as f:
        pickle.dump((train_idxs, test_idxs), f)




enc = OneHotEncoder(handle_unknown='ignore')
Y = np.array(Y).reshape(-1,1)
enc.fit(Y)
Y = enc.transform(Y).toarray()





Y.shape





Y[0]





Y[5560]





X_train = X[train_idxs]
X_test = X[test_idxs]
y_train = Y[train_idxs]
y_test = Y[test_idxs]









X_train.shape



X_test.shape




X_train[0]





y_train[0]







VIZ_ENABLED = True
NB_EPOCHS = 6
BATCH_SIZE = 128
LEARNING_RATE = .001
SOURCE_SAMPLES = 10



"""
A pure TensorFlow implementation of a Deep neural network.
"""
# pylint: disable=missing-docstring



class ModelBasicDeepNN(Model):
    def __init__(self, scope, nb_classes,**kwargs):
        del kwargs
        Model.__init__(self, scope, nb_classes, locals())
        self.fprop(tf.placeholder(tf.float32, [128, 1000]))
        self.params = self.get_params()
        
    def fprop(self, x, **kwargs):
        del kwargs
        with tf.variable_scope(self.scope, reuse=tf.AUTO_REUSE):
            y = tf.layers.flatten(x)
            y = tf.layers.dense(y,750,activation=tf.nn.relu)
            y = tf.layers.dense(y,512,activation=tf.nn.relu)
            y = tf.layers.dense(y,256,activation=tf.nn.relu)
            y = tf.layers.dense(y,128,activation=tf.nn.relu)
            y = tf.layers.dense(y,64,activation=tf.nn.relu)
            logits = tf.layers.dense(y, self.nb_classes,
              kernel_initializer=initializers.HeReLuNormalInitializer)
        return {self.O_LOGITS: logits,
                  self.O_PROBS: tf.nn.softmax(logits=logits)}




viz_enabled=False
nb_epochs=64
batch_size=128
source_samples=10000
learning_rate=0.01
report = AccuracyReport()




tf.set_random_seed(1234)
sess = tf.Session()




nb_classes = 2

x = tf.placeholder(tf.float32, shape=(None, 1000))
y = tf.placeholder(tf.float32, shape=(None, nb_classes))

nb_filters = 64
model = ModelBasicDeepNN('model1', nb_classes)






preds = model.get_logits(x)
loss = CrossEntropy(model, smoothing=0.1)
print("Defined TensorFlow model graph.")
train_params = {
  'nb_epochs': nb_epochs,
  'batch_size': batch_size,
  'learning_rate': learning_rate
}


sess.run(tf.global_variables_initializer())
rng = np.random.RandomState([2017, 8, 30])
X_train = X_train.astype('float32')
y_train = y_train.astype('float32')

train(sess, loss, X_train, y_train, args=train_params, rng=rng)
print(preds)
print("Training completed")


eval_params = {'batch_size': batch_size}
accuracy = model_eval(sess, x, y, preds, X_test, y_test, args=eval_params)
print('Test accuracy on legitimate test examples: {0}'.format(accuracy))
report.clean_train_clean_eval = accuracy



print('Crafting adversarial examples')

results = np.zeros((nb_classes, source_samples), dtype='i')

perturbations = np.zeros((nb_classes, source_samples), dtype='f')

jsma = SaliencyMapMethod(model, sess=sess)
jsma_params = {'theta': 1., 'gamma': 0.1,
             'clip_min': 0., 'clip_max': 1.,
             'y_target': None}

figure = None





y_pred = sess.run(model.get_logits(X_test.astype('float32')))



y_pred.shape



y_pred



y_pred[0]



y_pred[3]




# find malware samples location in x_test



xtest_malware_index=[]
for i in range(0,len(X_test)):
    if(y_test[i][1]==1):
        xtest_malware_index.append(i)




print(xtest_malware_index)



len(xtest_malware_index)



print("total samples in x_test is:",len(X_test))




print("total malware samples in x_test is:",len(xtest_malware_index))



#create new array for holding adversarial samples




x_test_adv=np.zeros((len(X_test),1000))




x_test_afterattack=np.zeros((len(X_test),1000))



crafted=[]



one_hot_target = np.zeros((1, nb_classes), dtype=np.float32)
one_hot_target




one_hot_target[0, 0] = 1
one_hot_target



one_hot_target[0, 0] = 1
one_hot_target


one_hot_target[0, 0] = 1
one_hot_target




x_test_mal_noisy = []
x_test_mal_clean = []
x_test_mal_noisy_idx = []
for i in range(0,len(X_test)):
    if(i in xtest_malware_index):
        sample =X_test[i:(i + 1)]
        one_hot_target = np.zeros((1, nb_classes), dtype=np.float32)
        one_hot_target[0, 0] = 1
        jsma_params['y_target'] = one_hot_target
        adv_x = jsma.generate_np(sample, **jsma_params)
        x_test_afterattack[i]=adv_x
        x_test_adv[i]=adv_x
        s = np.argmax(sess.run(model.get_logits(np.array([X_test[i]]).astype('float32'))))
        a = np.argmax(sess.run(model.get_logits(np.array([x_test_afterattack[i]]).astype('float32'))))
        if(s == 1 and a == 0):            
            x_test_mal_noisy.append(x_test_afterattack[i])
            np.save(str(i)+"Attacked_x_test_mal",x_test_afterattack[i])
            x_test_mal_clean.append(X_test[i])
            x_test_mal_noisy_idx.append(i)
    else:
        x_test_afterattack[i]=X_test[i]


len(x_test_mal_noisy)



len(x_test_mal_clean)



np.save("x_test_mal_noisy_JSMA_Drebin_1000",x_test_mal_noisy)

np.save("x_test_mal_clean_JSMA_Drebin_1000",x_test_mal_clean)



np.save("x_test_mal_noisy_idx_JSMA_Drebin_1000", x_test_mal_noisy_idx)




x_test_mal_noisy = np.load("x_test_mal_noisy_JSMA_Drebin_1000.npy")
x_test_mal_clean = np.load("x_test_mal_clean_JSMA_Drebin_1000.npy")
x_test_mal_noisy_idx = np.load("x_test_mal_noisy_idx_JSMA_Drebin_1000.npy")




X_test.shape




x_test_noised_benign = X_test
i = 0
for idx in x_test_mal_noisy_idx:
    x_test_noised_benign[idx] = x_test_mal_noisy[i]
    i = i+1




x_test_noised_benign.shape



len(x_test_mal_noisy)



Accuracy_Noisy = model_eval(sess, x, y, preds ,x_test_noised_benign,y_test, args=eval_params)
print(Accuracy_Noisy)




